{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/apchavezr/16.-Aprendizaje-Profundo-para-Ciencia-de-Datos/blob/main/LSTM_Prediccion_Palabra.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "257029e0",
      "metadata": {
        "id": "257029e0"
      },
      "source": [
        "# Ejemplo: Predicción de palabras con redes LSTM: Ejemplo ilustrativo\n",
        "\n",
        "Este notebook tiene como propósito demostrar, de manera paso a paso, el funcionamiento de una red neuronal de tipo LSTM (*Long Short-Term Memory*) para tareas de modelado de lenguaje. A través de una frase de entrada, el modelo intenta predecir la palabra siguiente, permitiendo observar el comportamiento de una arquitectura secuencial típica en procesamiento de lenguaje natural (NLP).\n",
        "\n",
        "**Escenario de ejemplo:**  \n",
        "Dada la secuencia de palabras `\"El clima está muy\"`, se busca predecir la palabra que más probablemente continúa la frase, como `\"frío\"`, `\"agradable\"` o `\"caliente\"`.\n",
        "\n",
        "Este ejercicio no se basa en un modelo previamente entrenado con corpus lingüísticos reales, por lo tanto, los resultados presentados no tienen valor predictivo en contexto real. El enfoque es exclusivamente didáctico para facilitar la comprensión de las entradas, estados ocultos y salidas en una red LSTM aplicada a texto.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "35cf4b5f",
      "metadata": {
        "id": "35cf4b5f"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Embedding, LSTM, Dense\n",
        "\n",
        "# Definir vocabulario simplificado\n",
        "vocabulario = [\"<PAD>\", \"El\", \"clima\", \"está\", \"muy\", \"frío\", \"caliente\", \"agradable\"]\n",
        "word2idx = {word: idx for idx, word in enumerate(vocabulario)}\n",
        "idx2word = {idx: word for word, idx in word2idx.items()}\n",
        "vocab_size = len(vocabulario)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6c7f0877",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6c7f0877",
        "outputId": "830f4a82-9f9a-4c5f-913f-c8ecae33d96c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Secuencia codificada: [[1 2 3 4]]\n"
          ]
        }
      ],
      "source": [
        "# Frase de entrada codificada: \"El clima está muy\"\n",
        "entrada = [\"El\", \"clima\", \"está\", \"muy\"]\n",
        "input_seq = np.array([[word2idx[w] for w in entrada]])\n",
        "print(\"Secuencia codificada:\", input_seq)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4dddd1a8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "4dddd1a8",
        "outputId": "8ca78596-4dcb-4919-b5aa-6afe0d158b12"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_1\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_1 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)              │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ embedding_1 (\u001b[38;5;33mEmbedding\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m8\u001b[0m)           │            \u001b[38;5;34m64\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)                   │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,    │         \u001b[38;5;34m1,600\u001b[0m │\n",
              "│                                 │ \u001b[38;5;34m16\u001b[0m), (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)]       │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)              │           \u001b[38;5;34m136\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ embedding_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)           │            <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,    │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,600</span> │\n",
              "│                                 │ <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)]       │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">136</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,800\u001b[0m (7.03 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,800</span> (7.03 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,800\u001b[0m (7.03 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,800</span> (7.03 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Parámetros\n",
        "embedding_dim = 8\n",
        "lstm_units = 16\n",
        "maxlen = 4  # longitud de la frase de entrada\n",
        "\n",
        "# Crear arquitectura LSTM\n",
        "input_layer = Input(shape=(maxlen,))\n",
        "embedding = Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=maxlen)(input_layer)\n",
        "lstm_out, state_h, state_c = LSTM(lstm_units, return_sequences=False, return_state=True)(embedding)\n",
        "output = Dense(vocab_size, activation='softmax')(lstm_out)\n",
        "\n",
        "modelo = Model(inputs=input_layer, outputs=output)\n",
        "modelo.compile(optimizer='adam', loss='categorical_crossentropy')\n",
        "modelo.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "866aa5dc",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "866aa5dc",
        "outputId": "bbce1c1e-797d-4b21-8df8-2b4912dfef28"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 216ms/step\n",
            "Palabra predicha: caliente\n"
          ]
        }
      ],
      "source": [
        "# Ejecutar predicción (sin entrenamiento)\n",
        "pred = modelo.predict(input_seq)\n",
        "predicted_idx = np.argmax(pred)\n",
        "predicted_word = idx2word[predicted_idx]\n",
        "\n",
        "print(\"Palabra predicha:\", predicted_word)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Conclusión\n",
        "\n",
        "Este ejercicio permitió observar cómo una red LSTM procesa una secuencia de palabras mediante el uso de memoria a corto y largo plazo. A diferencia de redes neuronales tradicionales, las LSTM conservan información contextual relevante a través del tiempo, lo cual es crucial en tareas de procesamiento de lenguaje natural."
      ],
      "metadata": {
        "id": "yFqLbI8L3paw"
      },
      "id": "yFqLbI8L3paw"
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}