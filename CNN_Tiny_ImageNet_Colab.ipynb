{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/apchavezr/16.-Aprendizaje-Profundo-para-Ciencia-de-Datos/blob/main/CNN_Tiny_ImageNet_Colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "48455285",
      "metadata": {
        "id": "48455285"
      },
      "source": [
        "# Entrenamiento de una CNN con Tiny ImageNet usando PyTorch\n",
        "Este notebook tiene como prop√≥sito entrenar una red neuronal convolucional (CNN) utilizando el conjunto de datos Tiny ImageNet, una versi√≥n reducida del famoso ImageNet. Esta pr√°ctica permite comprender el flujo de trabajo t√≠pico en deep learning, desde la carga de datos hasta la interpretaci√≥n de resultados."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d1b88c6c",
      "metadata": {
        "id": "d1b88c6c"
      },
      "source": [
        "## üéØ Objetivo\n",
        "- Entrenar un modelo CNN para clasificar im√°genes de 200 clases en el conjunto de datos Tiny ImageNet.\n",
        "- Visualizar el desempe√±o del modelo mediante curvas de p√©rdida y precisi√≥n.\n",
        "- Identificar errores comunes en la clasificaci√≥n y reflexionar sobre el impacto de la arquitectura y los datos."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "045595e4",
      "metadata": {
        "id": "045595e4"
      },
      "source": [
        "## üîß Paso 1: Preparar el entorno\n",
        "Instalaci√≥n de las librer√≠as necesarias para trabajar con PyTorch y torchvision."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b6e6df5d",
      "metadata": {
        "id": "b6e6df5d"
      },
      "outputs": [],
      "source": [
        "!pip install torch torchvision"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1c3dba3e",
      "metadata": {
        "id": "1c3dba3e"
      },
      "source": [
        "## üì• Paso 2: Descargar y descomprimir Tiny ImageNet\n",
        "Se descarga y extrae el dataset que contiene 100.000 im√°genes distribuidas en 200 clases."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "43efcaf6",
      "metadata": {
        "id": "43efcaf6"
      },
      "outputs": [],
      "source": [
        "!wget http://cs231n.stanford.edu/tiny-imagenet-200.zip\n",
        "!unzip -q tiny-imagenet-200.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b5ff5864",
      "metadata": {
        "id": "b5ff5864"
      },
      "source": [
        "## üìä Paso 3: Preprocesar y dividir el conjunto de datos\n",
        "Aplicamos transformaciones a las im√°genes (redimensionamiento, conversi√≥n a tensores) y creamos los `DataLoader` para entrenamiento y validaci√≥n."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "43fb12f6",
      "metadata": {
        "id": "43fb12f6"
      },
      "outputs": [],
      "source": [
        "\n",
        "import os\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "data_dir = 'tiny-imagenet-200'\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((64, 64)),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "train_data = datasets.ImageFolder(os.path.join(data_dir, 'train'), transform=transform)\n",
        "train_loader = DataLoader(train_data, batch_size=64, shuffle=True)\n",
        "\n",
        "val_data = datasets.ImageFolder(os.path.join(data_dir, 'val'), transform=transform)\n",
        "val_loader = DataLoader(val_data, batch_size=64, shuffle=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "47e84089",
      "metadata": {
        "id": "47e84089"
      },
      "source": [
        "## üß† Paso 4: Definir una arquitectura basada en ResNet\n",
        "Usamos una red ResNet-18 adaptada para 200 clases, propia del conjunto Tiny ImageNet."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b29a146d",
      "metadata": {
        "id": "b29a146d"
      },
      "outputs": [],
      "source": [
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.models as models\n",
        "\n",
        "model = models.resnet18(pretrained=False)\n",
        "model.fc = nn.Linear(model.fc.in_features, 200)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "45594f4e",
      "metadata": {
        "id": "45594f4e"
      },
      "source": [
        "## ‚öôÔ∏è Paso 5: Entrenamiento del modelo\n",
        "Entrenamos el modelo durante 5 √©pocas usando `Adam` como optimizador y `CrossEntropyLoss` como funci√≥n de p√©rdida."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cc4e331c",
      "metadata": {
        "id": "cc4e331c"
      },
      "outputs": [],
      "source": [
        "\n",
        "import torch.optim as optim\n",
        "from tqdm import tqdm\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = model.to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "for epoch in range(5):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    for images, labels in tqdm(train_loader):\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "    print(f\"√âpoca {epoch+1}, p√©rdida: {running_loss / len(train_loader)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b731c525",
      "metadata": {
        "id": "b731c525"
      },
      "source": [
        "## üîç Paso 6: Evaluar e interpretar errores del modelo\n",
        "Identificamos algunas predicciones incorrectas para entender los desaf√≠os del modelo y los datos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "45b12213",
      "metadata": {
        "id": "45b12213"
      },
      "outputs": [],
      "source": [
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "model.eval()\n",
        "wrong_images = []\n",
        "wrong_preds = []\n",
        "correct_labels = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in val_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = model(images)\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "        for i in range(len(labels)):\n",
        "            if preds[i] != labels[i]:\n",
        "                wrong_images.append(images[i].cpu())\n",
        "                wrong_preds.append(preds[i].cpu())\n",
        "                correct_labels.append(labels[i].cpu())\n",
        "        if len(wrong_images) >= 5:\n",
        "            break\n",
        "\n",
        "for i in range(5):\n",
        "    plt.imshow(np.transpose(wrong_images[i].numpy(), (1, 2, 0)))\n",
        "    plt.title(f\"Predicci√≥n: {wrong_preds[i]}, Real: {correct_labels[i]}\")\n",
        "    plt.axis('off')\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2e587928",
      "metadata": {
        "id": "2e587928"
      },
      "source": [
        "## ‚úÖ Conclusiones\n",
        "- El uso de CNN permite aprender representaciones directamente desde los datos, eliminando la necesidad de extraer caracter√≠sticas manualmente.\n",
        "- La calidad de los datos y el tama√±o del conjunto son determinantes en el rendimiento del modelo.\n",
        "- Este tipo de ejercicios pr√°cticos refuerzan la comprensi√≥n de los elementos cr√≠ticos en el entrenamiento de modelos profundos: arquitectura, datos, m√©tricas y errores."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}